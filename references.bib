@article{RichardBellman1957AProcess,
    title = {{A Markovian Decision Process}},
    year = {1957},
    journal = {Indiana Univ. Math. J.},
    author = {{Richard Bellman}},
    number = {4},
    volume = {6}
}

@techreport{NachumBridgingLearning,
    title = {{Bridging the Gap Between Value and Policy Based Reinforcement Learning}},
    author = {Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Brain, Google},
    url = {https://github.com/tensorflow/models/tree/}
}

@article{vanHasselt2015DeepQ-learning,
    title = {{Deep Reinforcement Learning with Double Q-learning}},
    year = {2015},
    author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
    month = {9},
    url = {http://arxiv.org/abs/1509.06461},
    arxivId = {1509.06461}
}

@inproceedings{Zakharenkov2021DeepVizDoom,
    title = {{Deep Reinforcement Learning with DQN vs. PPO in VizDoom}},
    year = {2021},
    booktitle = {21st IEEE International Symposium on Computational Intelligence and Informatics, CINTI 2021 - Proceedings},
    author = {Zakharenkov, Anton and Makarov, Ilya},
    pages = {131--136},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    isbn = {9781665426848},
    doi = {10.1109/CINTI53070.2021.9668479},
    keywords = {DQN, Deep reinforcement learning, PPO, VizDoom}
}

@article{Dabney2017DistributionalRegression,
    title = {{Distributional Reinforcement Learning with Quantile Regression}},
    year = {2017},
    author = {Dabney, Will and Rowland, Mark and Bellemare, Marc G. and Munos, RÃ©mi},
    month = {10},
    url = {http://arxiv.org/abs/1710.10044},
    arxivId = {1710.10044}
}

@techreport{VanHasselt2010DoubleQ-learning,
    title = {{Double Q-learning}},
    year = {2010},
    author = {Van Hasselt, Hado}
}

@techreport{NicholGottaRL,
    title = {{Gotta Learn Fast: A New Benchmark for Generalization in RL}},
    author = {Nichol, Alex and Pfau, Vicki and Hesse, Christopher and Klimov, Oleg and Openai, John Schulman},
    url = {https://www.libretro.com/index.php/api}
}

@techreport{Thrun1993IssuesLearning,
    title = {{Issues in Using Function Approximation for Reinforcement Learning}},
    year = {1993},
    author = {Thrun, Sebastian and Schwartz, Anton}
}

@inproceedings{Huang2020Model-basedLearning,
    title = {{Model-based or model-free, a review of approaches in reinforcement learning}},
    year = {2020},
    booktitle = {Proceedings - 2020 International Conference on Computing and Data Science, CDS 2020},
    author = {Huang, Qingyan},
    month = {8},
    pages = {219--221},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    isbn = {9781728171067},
    doi = {10.1109/CDS49703.2020.00051},
    keywords = {Model-based RL, Model-free RL, Q-learning, Reinforcement learning, Review}
}

@article{Zhang2019Multi-AgentAlgorithms,
    title = {{Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms}},
    year = {2019},
    author = {Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
    month = {11},
    url = {http://arxiv.org/abs/1911.10635},
    arxivId = {1911.10635}
}

@misc{OpenAIOpenAIOptimisation,
    title = {{OpenAI Intro To Policy Optimisation}},
    booktitle = {https://spinningup.openai.com/en/latest/spinningup/rl{\_}intro3.html},
    author = {{OpenAI}}
}

@techreport{MnihPlayingLearning,
    title = {{Playing Atari with Deep Reinforcement Learning}},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin}
}

@article{Schulman2017ProximalAlgorithms,
    title = {{Proximal Policy Optimization Algorithms}},
    year = {2017},
    author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
    month = {7},
    url = {http://arxiv.org/abs/1707.06347},
    arxivId = {1707.06347}
}

@techreport{Watkins1992Q-Learning,
    title = {{Q-Learning}},
    year = {1992},
    author = {Watkins, Christopher J C H and Dayan, Peter},
    pages = {279--292},
    volume = {8},
    keywords = {0{\~{}}-learning, asynchronous dynamic programming, reinforcement learning, temporal differences}
}

@techreport{SuttonReinforcementProgress,
    title = {{Reinforcement Learning: An Introduction Second edition, in progress}},
    author = {Sutton, Richard S and Barto, Andrew G}
}

@article{RichardBellman1954TheProgramming,
    title = {{The Theory of Dynamic Programming}},
    year = {1954},
    author = {{Richard Bellman}}
}

@techreport{JannerWhenOptimization,
    title = {{When to Trust Your Model: Model-Based Policy Optimization}},
    author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey}
}